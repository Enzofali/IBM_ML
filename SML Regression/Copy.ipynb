{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Project: Supervised Machine Learning Regression\n",
    "\n",
    "### Objective:\n",
    "\n",
    "The objective of this report is to deepen in the interpretation of the data collected corresponding to housing sales in Ames Iowa USA. From the results obtained, we will be able to analyze the influence of the different features to determine the sailing price. It is relevant to determine the influences of the study variables. With this information, we will be able to maximize the benefit of future investments in real estate projects in the area.\n",
    "\n",
    "### Description of the Data Set and its attributes (/////Brief description of the data set you chose and a summary of its attributes.)\n",
    "\n",
    "Among the main attributes of the data can be found those described below.\n",
    "\n",
    "### Predictor\n",
    "\n",
    "* SalePrice: The property's sale price in dollars. \n",
    "\n",
    "### Features\n",
    "Features with high impact:\n",
    "* MoSold: Month Sold\n",
    "* YrSold: Year Sold   \n",
    "* SaleType: Type of sale\n",
    "* SaleCondition: Condition of sale\n",
    "* MSSubClass: The building class\n",
    "* MSZoning: The general zoning classification\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data & Data Cleaning (//////Brief summary of data exploration and actions taken for data cleaning and feature engineering.)\n",
    "# Initial plan for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>8</td>\n",
       "      <td>856.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>7</td>\n",
       "      <td>756.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>9</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
       "0     856.0     854.0        0.0  None             3     1Fam       TA   \n",
       "1    1262.0       0.0        0.0  None             3     1Fam       TA   \n",
       "2     920.0     866.0        0.0  None             3     1Fam       TA   \n",
       "3     961.0     756.0        0.0  None             3     1Fam       Gd   \n",
       "4    1145.0    1053.0        0.0  None             4     1Fam       TA   \n",
       "\n",
       "  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ... ScreenPorch Street  TotRmsAbvGrd  \\\n",
       "0           No       706.0         0.0  ...         0.0   Pave             8   \n",
       "1           Gd       978.0         0.0  ...         0.0   Pave             6   \n",
       "2           Mn       486.0         0.0  ...         0.0   Pave             6   \n",
       "3           No       216.0         0.0  ...         0.0   Pave             7   \n",
       "4           Av       655.0         0.0  ...         0.0   Pave             9   \n",
       "\n",
       "   TotalBsmtSF Utilities  WoodDeckSF YearBuilt YearRemodAdd YrSold SalePrice  \n",
       "0        856.0    AllPub         0.0      2003         2003   2008  208500.0  \n",
       "1       1262.0    AllPub       298.0      1976         1976   2007  181500.0  \n",
       "2        920.0    AllPub         0.0      2001         2002   2008  223500.0  \n",
       "3        756.0    AllPub         0.0      1915         1970   2006  140000.0  \n",
       "4       1145.0    AllPub       192.0      2000         2000   2008  250000.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1379 entries, 0 to 1378\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   1stFlrSF       1379 non-null   float64\n",
      " 1   2ndFlrSF       1379 non-null   float64\n",
      " 2   3SsnPorch      1379 non-null   float64\n",
      " 3   Alley          1379 non-null   object \n",
      " 4   BedroomAbvGr   1379 non-null   int64  \n",
      " 5   BldgType       1379 non-null   object \n",
      " 6   BsmtCond       1379 non-null   object \n",
      " 7   BsmtExposure   1379 non-null   object \n",
      " 8   BsmtFinSF1     1379 non-null   float64\n",
      " 9   BsmtFinSF2     1379 non-null   float64\n",
      " 10  BsmtFinType1   1379 non-null   object \n",
      " 11  BsmtFinType2   1379 non-null   object \n",
      " 12  BsmtFullBath   1379 non-null   int64  \n",
      " 13  BsmtHalfBath   1379 non-null   int64  \n",
      " 14  BsmtQual       1379 non-null   object \n",
      " 15  BsmtUnfSF      1379 non-null   float64\n",
      " 16  CentralAir     1379 non-null   object \n",
      " 17  Condition1     1379 non-null   object \n",
      " 18  Condition2     1379 non-null   object \n",
      " 19  Electrical     1379 non-null   object \n",
      " 20  EnclosedPorch  1379 non-null   float64\n",
      " 21  ExterCond      1379 non-null   object \n",
      " 22  ExterQual      1379 non-null   object \n",
      " 23  Exterior1st    1379 non-null   object \n",
      " 24  Exterior2nd    1379 non-null   object \n",
      " 25  Fence          1379 non-null   object \n",
      " 26  FireplaceQu    1379 non-null   object \n",
      " 27  Fireplaces     1379 non-null   int64  \n",
      " 28  Foundation     1379 non-null   object \n",
      " 29  FullBath       1379 non-null   int64  \n",
      " 30  Functional     1379 non-null   object \n",
      " 31  GarageArea     1379 non-null   float64\n",
      " 32  GarageCars     1379 non-null   int64  \n",
      " 33  GarageCond     1379 non-null   object \n",
      " 34  GarageFinish   1379 non-null   object \n",
      " 35  GarageQual     1379 non-null   object \n",
      " 36  GarageType     1379 non-null   object \n",
      " 37  GarageYrBlt    1379 non-null   float64\n",
      " 38  GrLivArea      1379 non-null   float64\n",
      " 39  HalfBath       1379 non-null   int64  \n",
      " 40  Heating        1379 non-null   object \n",
      " 41  HeatingQC      1379 non-null   object \n",
      " 42  HouseStyle     1379 non-null   object \n",
      " 43  KitchenAbvGr   1379 non-null   int64  \n",
      " 44  KitchenQual    1379 non-null   object \n",
      " 45  LandContour    1379 non-null   object \n",
      " 46  LandSlope      1379 non-null   object \n",
      " 47  LotArea        1379 non-null   float64\n",
      " 48  LotConfig      1379 non-null   object \n",
      " 49  LotFrontage    1379 non-null   float64\n",
      " 50  LotShape       1379 non-null   object \n",
      " 51  LowQualFinSF   1379 non-null   float64\n",
      " 52  MSSubClass     1379 non-null   int64  \n",
      " 53  MSZoning       1379 non-null   object \n",
      " 54  MasVnrArea     1379 non-null   float64\n",
      " 55  MasVnrType     1379 non-null   object \n",
      " 56  MiscFeature    1379 non-null   object \n",
      " 57  MiscVal        1379 non-null   float64\n",
      " 58  MoSold         1379 non-null   int64  \n",
      " 59  Neighborhood   1379 non-null   object \n",
      " 60  OpenPorchSF    1379 non-null   float64\n",
      " 61  OverallCond    1379 non-null   int64  \n",
      " 62  OverallQual    1379 non-null   int64  \n",
      " 63  PavedDrive     1379 non-null   object \n",
      " 64  PoolArea       1379 non-null   float64\n",
      " 65  PoolQC         1379 non-null   object \n",
      " 66  RoofMatl       1379 non-null   object \n",
      " 67  RoofStyle      1379 non-null   object \n",
      " 68  SaleCondition  1379 non-null   object \n",
      " 69  SaleType       1379 non-null   object \n",
      " 70  ScreenPorch    1379 non-null   float64\n",
      " 71  Street         1379 non-null   object \n",
      " 72  TotRmsAbvGrd   1379 non-null   int64  \n",
      " 73  TotalBsmtSF    1379 non-null   float64\n",
      " 74  Utilities      1379 non-null   object \n",
      " 75  WoodDeckSF     1379 non-null   float64\n",
      " 76  YearBuilt      1379 non-null   int64  \n",
      " 77  YearRemodAdd   1379 non-null   int64  \n",
      " 78  YrSold         1379 non-null   int64  \n",
      " 79  SalePrice      1379 non-null   float64\n",
      "dtypes: float64(21), int64(16), object(43)\n",
      "memory usage: 862.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "filepath = 'Ames_Housing_Sales.csv'\n",
    "data = pd.read_csv(filepath)\n",
    "display(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     43\n",
       "float64    21\n",
       "int64      16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con sin ohc, sin boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr = LinearRegression() \n",
    "s = StandardScaler() \n",
    "\n",
    "object_columns = data.columns[data.dtypes == object]\n",
    "new_data = data.drop(object_columns, axis=1)\n",
    "\n",
    "features = new_data.drop('SalePrice', axis=1)\n",
    "target = new_data.SalePrice\n",
    "#target = log_SalePrice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=72018)\n",
    "X_train_s = s.fit_transform(X_train)\n",
    "lr.fit(X_train_s, y_train) \n",
    "X_test_s = s.transform(X_test) \n",
    "y_pred = lr.predict(X_test_s)\n",
    "#r2_score(np.exp(y_pred) - 1,np.exp(y_test) - 1)\n",
    "r2_score(y_pred ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con ohc, sin boxcox\n",
    "features = data_ohc.drop('SalePrice', axis=1)\n",
    "target = data_ohc.SalePrice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=72018)\n",
    "X_train_s = s.fit_transform(X_train)\n",
    "lr.fit(X_train_s, y_train) \n",
    "X_test_s = s.transform(X_test) \n",
    "y_pred = lr.predict(X_test_s)\n",
    "r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression assumes a normally distributed residuals which can be aided by transforming y variable. Let's try some common transformations to try and get y to be normally distributed: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_result = boxcox(boston_data.MEDV) #Return a dataset transformed by a Box-Cox power transformation.\n",
    "boxcox_medv = bc_result[0] # Box-Cox power transformed array.\n",
    "lam = bc_result[1] # If the lmbda parameter is None, the second returned argument is the lambda that maximizes the log-likelihood function.\n",
    "print(lam, '\\n', boxcox_medv)\n",
    "boston_data.MEDV.hist();\n",
    "plt.hist(boxcox_medv);\n",
    "print(normaltest(boxcox_medv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (StandardScaler, \n",
    "                                   PolynomialFeatures)\n",
    "from scipy.special import inv_boxcox\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"MEDV\"\n",
    "\n",
    "X = boston_data.drop(y_col, axis=1)\n",
    "y = boston_data[y_col]\n",
    "X.head()\n",
    "\n",
    "pf = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_pf = pf.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(X_pf.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pf, y, test_size=0.3, random_state=72018)\n",
    "\n",
    "s = StandardScaler() # Standardize features by removing the mean and scaling to unit variance.\n",
    "X_train_s = s.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es estrictamente necesario pero, mientras mas se asemeje la distribucion de nuestra variable a predecir a una normal gausseana, mejor regresion lineal podra ser obtenida. \n",
    "\n",
    "When you're working with linear regression, scaling won't actually affect the outcome, won't affect your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_result2 = boxcox(y_train)\n",
    "y_train_bc = bc_result2[0]\n",
    "lam2 = bc_result2[1]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_s, y_train_bc) # .fit es usado para que la regresion lineal aprenda los parametros del modelo.\n",
    "X_test_s = s.transform(X_test) # Solo usamos .transform dado que ya hicimos: X_train_s = s.fit_transform(X_train)\n",
    "# Unicamente se puede estandarizar las variables luego de dividirlas para el entrenamiento y la prueba. Boxcox se puede hacer antes o despues indiferentemente. \n",
    "y_pred_bc = lr.predict(X_test_s)\n",
    "y_pred_tran = inv_boxcox(y_pred_bc,lam2)\n",
    "r2_score(y_pred_tran,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more parameters we use the more likely to overfit the data. We're able to come up with a variation or different coefficients to exactly fit to your training set that may not replicate out in the real world.\n",
    "A good indicator is a big gap between the training set error and the test set error.\n",
    "\n",
    "Note that the error values on the one-hot encoded data are very different for the train and test data. In particular, the errors on the test data are much higher. Based on the lecture, this is because the one-hot encoded model is overfitting the data. We will learn how to deal with issues like this in the next lesson.\n",
    "\n",
    "         no enc  /   one-hot enc\n",
    "\n",
    "train\t/   1.131507e+09\t/   3.177269e+08\n",
    "\n",
    "test\t/   1.372182e+09\t/   4.053947e+16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data_ohc = data.copy()\n",
    "\n",
    "# df = pd.get_dummies(df, columns = one_hot_encode_cols, drop_first = True) \n",
    "\n",
    "ohc = OneHotEncoder(drop = 'first') # High coeficents interpretability\n",
    "categorical_cols = data.columns[data.dtypes == object]\n",
    "for col in categorical_cols:\n",
    "    new_dat = ohc.fit_transform(data_ohc[[col]]) # When working with sklearn tranformers and predictors we need to ensure that we are working with TWO DIMENSIONS. Return a Sparse Matrix.\n",
    "    data_ohc = data_ohc.drop(col, axis=1) # Drop original column from the dataframe\n",
    "    cats = ohc.categories_ # Get names of all unique values in columns\n",
    "    new_cols = ['_'.join([col,cat]) for cat in cats[0]] # Create column names for each one column by value\n",
    "    new_df = pd.DataFrame(new_dat.toarray(),columns=new_cols) # Create the new dataframe from the Sparse Matrix    \n",
    "    data_ohc = pd.concat([data_ohc, new_df], axis=1) # Append the new data to the dataframe, axis=1: to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(shuffle=True, random_state=72018, n_splits=3)\n",
    "\n",
    "scores = []\n",
    "lr = LinearRegression()\n",
    "s = StandardScaler()\n",
    "estimator = Pipeline([(\"scaler\", s),\n",
    "                      (\"regression\", lr)])\n",
    "                      \n",
    "predictions = cross_val_predict(estimator, X, y, cv=kf)\n",
    "predictions\n",
    "r2_score(y, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `cross_val_predict` doesn't use the same model for all steps; the predictions for each row are made when that row is in the validation set. We really have the collected results of 3 (i.e. `kf.num_splits`) different models. When we are done, `estimator` is still not fitted. If we want to predict on _new_ data, we still have to train our `estimator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enzof\\Desktop\\Python Projects\\2 Supervised Machine Learning Regression\\6 Course Project\\2 SMLRegression-CourseProject.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=2'>3</a>\u001b[0m \u001b[39m# Same estimator as before\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=3'>4</a>\u001b[0m estimator \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=4'>5</a>\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mpolynomial_features\u001b[39m\u001b[39m\"\u001b[39m, PolynomialFeatures()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=5'>6</a>\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m\"\u001b[39m, StandardScaler()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=6'>7</a>\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mridge_regression\u001b[39m\u001b[39m\"\u001b[39m, Ridge())])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=8'>9</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpolynomial_features__degree\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mridge_regression__alpha\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mgeomspace(\u001b[39m4\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=11'>12</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enzof/Desktop/Python%20Projects/2%20Supervised%20Machine%20Learning%20Regression/6%20Course%20Project/2%20SMLRegression-CourseProject.ipynb#ch0000021?line=13'>14</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator, params, cv\u001b[39m=\u001b[39mkf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Same estimator as before\n",
    "estimator = Pipeline([\n",
    "        (\"polynomial_features\", PolynomialFeatures()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge_regression\", Ridge())])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3],\n",
    "    'ridge_regression__alpha': np.geomspace(4, 20, 30)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator, params, cv=kf)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_, grid.best_params_\n",
    "\n",
    "df_importances = pd.DataFrame(zip(estimator.named_steps[\"polynomial_features\"].get_feature_names(),\n",
    "                 grid.best_estimator_.named_steps['ridge_regression'].coef_)).sort_values(by=1)\n",
    "\n",
    "y_predict = grid.predict(X)\n",
    "r2_score(y, y_predict)\n",
    "\n",
    "pd.DataFrame(grid.cv_results_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(ytrue, ypredicted): # Root Mean Squared Error\n",
    "    return np.sqrt(mean_squared_error(ytrue, ypredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDGE\n",
    "from sklearn.linear_model import RidgeCV\n",
    "# The regularization functions and Sk-learn each contain versions that have cross-validation built in.\n",
    "# So that's the same as GridSearchCV with Ridge as the model that we're working with.\n",
    "\n",
    "alphas = [0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]\n",
    "\n",
    "ridgeCV = RidgeCV(alphas=alphas, \n",
    "                  cv=4).fit(X_train, y_train) # .fit(X,y) not .fit(X_train, y_train)????????????????????????????????????????????????????\n",
    "# alphas: hyperparameters\n",
    "# cv = cross validation number of train and tests splits\n",
    "\n",
    "ridgeCV_rmse = rmse(y_test, ridgeCV.predict(X_test))\n",
    "\n",
    "print(ridgeCV.alpha_, int(ridgeCV_rmse))\n",
    "# ridgeCV.alpha_: is the alpha value that optimizes the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "alphas2 = np.array([0.005, 0.05, 0.1, 1, 5, 20, 50, 80, 100, 120, 140])\n",
    "\n",
    "lassoCV = LassoCV(alphas=alphas2,\n",
    "                  max_iter=5e4,\n",
    "                  cv=3).fit(X_train, y_train)\n",
    "\n",
    "lassoCV_rmse = rmse(y_test, lassoCV.predict(X_test))\n",
    "\n",
    "print(lassoCV.alpha_, int(lassoCV_rmse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net is going to take our lambda value, and attribute a portion of it to to your Ridge, to your coefficient squared, and a portion of it to the absolute value of your coefficients. So 0.1 will be a lot of weight on the Ridge, whereas 0.9 will be a lot of weight on the Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELASTIC-NET\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "l1_ratios = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "elasticNetCV = ElasticNetCV(alphas=alphas2, \n",
    "                            l1_ratio=l1_ratios,\n",
    "                            max_iter=1e4,\n",
    "                            cv=3).fit(X_train, y_train)\n",
    "                            \n",
    "elasticNetCV_rmse = rmse(y_test, elasticNetCV.predict(X_test))\n",
    "\n",
    "print(elasticNetCV.alpha_, elasticNetCV.l1_ratio_, int(elasticNetCV_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether you want to reduce a lot of the coefficients, and do feature selection, then need to use Lasso. Lasso takes longer because it uses something called gradient descent to step through until it gets to the optimal solution.\n",
    "\n",
    "Whether you wanted to run very quickly, you'd want to use Ridge. \n",
    "\n",
    "And if you want to find that optimal balance, you may want to use elastic net."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ab0c7ee03d3e0adf79e17425ea777ec1b9c6310b2b6bce963858db947f2e5a8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
